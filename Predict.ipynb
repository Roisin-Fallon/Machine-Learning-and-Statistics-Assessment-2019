{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library for generating random variables\n",
    "import numpy as np\n",
    "\n",
    "# Import the library for handling data\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation library\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the libraries for T-test and ANOVA\n",
    "import scipy.stats as stats\n",
    "\n",
    "# inport statsmodels.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# To plot the graph embedded in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Boston Housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# Commented out the print statement here as it is difficult to read and interupt.\n",
    "# print(boston)  \n",
    "\n",
    "# Adapted from: https://github.com/Tsmith5151/Boston-Housing-Prices/blob/master/boston_housing.ipynb\n",
    "\n",
    "#Values\n",
    "price = boston.target                                   # Target values\n",
    "feature = boston.data                                   # Attributes values\n",
    "\n",
    "# Store in DataFrame\n",
    "attributes = boston.feature_names                       # Feature names\n",
    "data = pd.DataFrame(feature, columns = attributes)\n",
    "target = pd.DataFrame(price, columns =['MEDV'])\n",
    "df = pd.concat([data, target,], axis = 1)               # concat data/target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT\n",
    "\n",
    "There are 13 features. Here we will remove the columns that will not be used to predict the target variable.\n",
    "\n",
    "* 16 data points have an 'MEDV' value of 50.0. These data points likely contain missing or censored values and have been removed.\n",
    "* 1 data point has an 'RM' value of 8.78. This data point can be considered an outlier and has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://books.google.ie/books?id=7zhDDwAAQBAJ&pg=PT358&lpg=PT358&dq=X+%3D+tips%5B%27total_bill%27%5D.values.reshape(-1,1)+Y+%3D+tips%5B%27tip%27%5D.values.reshape(-1,1)&source=bl&ots=vHyyJ7sVqy&sig=ACfU3U1WQO1y3kwv3o_xi-PomAdcojqz9g&hl=en&sa=X&ved=2ahUKEwjtuMrfmovmAhV1o3EKHaAfBpgQ6AEwAHoECAkQAQ#v=onepage&q=X%20%3D%20tips%5B'total_bill'%5D.values.reshape(-1%2C1)%20Y%20%3D%20tips%5B'tip'%5D.values.reshape(-1%2C1)&f=false\n",
    "# Spliting target variable and independent variables\n",
    "# Adapted from: https://books.google.ie/books?id=7zhDDwAAQBAJ&pg=PT358&lpg=PT358&dq=X+%3D+tips%5B%27total_bill%27%5D.values.reshape(-1,1)+Y+%3D+tips%5B%27tip%27%5D.values.reshape(-1,1)&source=bl&ots=vHyyJ7sVqy&sig=ACfU3U1WQO1y3kwv3o_xi-PomAdcojqz9g&hl=en&sa=X&ved=2ahUKEwjtuMrfmovmAhV1o3EKHaAfBpgQ6AEwAHoECAkQAQ#v=onepage&q=X%20%3D%20tips%5B'total_bill'%5D.values.reshape(-1%2C1)%20Y%20%3D%20tips%5B'tip'%5D.values.reshape(-1%2C1)&f=false\n",
    "\n",
    "X = df[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    " 'B', 'LSTAT']].values        \n",
    "\n",
    "y = df[[\"MEDV\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#features= pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "features= scaler.fit_transform(features)\n",
    "prices= prices.values.reshape(-1,1)\n",
    "#prices = pd.DataFrame(scaler.fit_transform(prices), columns=prices.columns)\n",
    "prices = scaler.fit_transform(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size                 : 354\n",
      "Test Size                     : 152\n",
      "Total Dataset Size            : 506\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset: 66% data to the training set and 33% data to the test set\n",
    "# random_state sets a seed to the random generator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training Size                 :\", len(X_train))\n",
    "print(\"Test Size                     :\", len(X_test))\n",
    "print(\"Total Dataset Size            :\",len(X_train) + len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error       : 21.52\n",
      "Mean Absolute Error     : 3.16\n",
      "Root Mean Square Error  : 4.64\n",
      "R-Squared               : 0.74\n",
      "Score                   : 0.71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.146689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.8</td>\n",
       "      <td>17.392124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.078599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.6</td>\n",
       "      <td>23.036927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.599433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.5</td>\n",
       "      <td>24.822862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.530570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.865435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.2</td>\n",
       "      <td>21.801723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.5</td>\n",
       "      <td>19.225712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.8</td>\n",
       "      <td>26.191920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.277339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.2</td>\n",
       "      <td>5.615964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.0</td>\n",
       "      <td>40.448880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.1</td>\n",
       "      <td>17.576959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.2</td>\n",
       "      <td>27.443191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29.1</td>\n",
       "      <td>30.171596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.7</td>\n",
       "      <td>10.940558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.4</td>\n",
       "      <td>24.020831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.2</td>\n",
       "      <td>18.076938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.8</td>\n",
       "      <td>15.934748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.3</td>\n",
       "      <td>23.126140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.9</td>\n",
       "      <td>14.560521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21.7</td>\n",
       "      <td>22.334825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.3</td>\n",
       "      <td>19.325763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.8</td>\n",
       "      <td>3.379371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>19.2</td>\n",
       "      <td>23.904658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25.3</td>\n",
       "      <td>25.817921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>20.4</td>\n",
       "      <td>23.110205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.1</td>\n",
       "      <td>25.334892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>37.9</td>\n",
       "      <td>33.355452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>15.6</td>\n",
       "      <td>20.607245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>45.4</td>\n",
       "      <td>38.477267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15.7</td>\n",
       "      <td>13.973985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>22.6</td>\n",
       "      <td>25.219240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>14.5</td>\n",
       "      <td>17.809466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>18.7</td>\n",
       "      <td>20.634374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>17.8</td>\n",
       "      <td>9.802674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>16.1</td>\n",
       "      <td>21.079536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>20.6</td>\n",
       "      <td>22.337842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>31.6</td>\n",
       "      <td>32.323819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>29.1</td>\n",
       "      <td>31.486949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>15.6</td>\n",
       "      <td>15.466213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>17.5</td>\n",
       "      <td>16.862428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>22.5</td>\n",
       "      <td>28.993305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>19.4</td>\n",
       "      <td>24.954679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>19.3</td>\n",
       "      <td>16.736336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>8.5</td>\n",
       "      <td>6.128584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20.6</td>\n",
       "      <td>26.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>17.0</td>\n",
       "      <td>23.340072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>17.1</td>\n",
       "      <td>17.403672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>14.5</td>\n",
       "      <td>13.385941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>50.0</td>\n",
       "      <td>39.983425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.3</td>\n",
       "      <td>16.682863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.6</td>\n",
       "      <td>18.285618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0      23.6  28.648960\n",
       "1      32.4  36.495014\n",
       "2      13.6  15.411193\n",
       "3      22.8  25.403213\n",
       "4      16.1  18.855280\n",
       "5      20.0  23.146689\n",
       "6      17.8  17.392124\n",
       "7      14.0  14.078599\n",
       "8      19.6  23.036927\n",
       "9      16.8  20.599433\n",
       "10     21.5  24.822862\n",
       "11     18.9  18.530570\n",
       "12      7.0  -6.865435\n",
       "13     21.2  21.801723\n",
       "14     18.5  19.225712\n",
       "15     29.8  26.191920\n",
       "16     18.8  20.277339\n",
       "17     10.2   5.615964\n",
       "18     50.0  40.448880\n",
       "19     14.1  17.576959\n",
       "20     25.2  27.443191\n",
       "21     29.1  30.171596\n",
       "22     12.7  10.940558\n",
       "23     22.4  24.020831\n",
       "24     14.2  18.076938\n",
       "25     13.8  15.934748\n",
       "26     20.3  23.126140\n",
       "27     14.9  14.560521\n",
       "28     21.7  22.334825\n",
       "29     18.3  19.325763\n",
       "..      ...        ...\n",
       "122     8.8   3.379371\n",
       "123    19.2  23.904658\n",
       "124    25.3  25.817921\n",
       "125    20.4  23.110205\n",
       "126    23.1  25.334892\n",
       "127    37.9  33.355452\n",
       "128    15.6  20.607245\n",
       "129    45.4  38.477267\n",
       "130    15.7  13.973985\n",
       "131    22.6  25.219240\n",
       "132    14.5  17.809466\n",
       "133    18.7  20.634374\n",
       "134    17.8   9.802674\n",
       "135    16.1  21.079536\n",
       "136    20.6  22.337842\n",
       "137    31.6  32.323819\n",
       "138    29.1  31.486949\n",
       "139    15.6  15.466213\n",
       "140    17.5  16.862428\n",
       "141    22.5  28.993305\n",
       "142    19.4  24.954679\n",
       "143    19.3  16.736336\n",
       "144     8.5   6.128584\n",
       "145    20.6  26.659900\n",
       "146    17.0  23.340072\n",
       "147    17.1  17.403672\n",
       "148    14.5  13.385941\n",
       "149    50.0  39.983425\n",
       "150    14.3  16.682863\n",
       "151    12.6  18.285618\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Specify the predictor X and the response y \n",
    "lr.fit(X_train, y_train)\n",
    "predict = lr.predict(X_test)\n",
    "\n",
    "print(\"Mean Square Error       : {:.2f}\".format(mean_squared_error(y_test, predict)))\n",
    "print(\"Mean Absolute Error     : {:.2f}\".format(metrics.mean_absolute_error(y_test, y_pred)))\n",
    "print(\"Root Mean Square Error  : {:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "print(\"R-Squared               : {:.2f}\".format(lr.score(X_train,y_train)))\n",
    "print(\"Score                   : {:.2f}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "# Determine the how accurate this algorthm is at predicting values\n",
    "y_predict = lr.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/ianmcloughlin/jupyter-teaching-notebooks/blob/master/keras-and-iris.ipynb\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with x neurons and an input layer with 4.\n",
    "model.add(kr.layers.Dense(units=30, activation='relu', input_dim=4))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with x neurons and an input layer with 4.\n",
    "model.add(kr.layers.Dense(units=30, activation='relu', input_dim=4))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network.\n",
    "model.fit(inputs_train_white, outputs_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
